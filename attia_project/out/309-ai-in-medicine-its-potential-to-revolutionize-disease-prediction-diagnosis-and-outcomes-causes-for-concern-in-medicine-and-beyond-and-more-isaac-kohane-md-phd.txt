Starting point is 00:00:00
Hey everyone, welcome to the Drive Podcast. I'm your host, Peter Attia. This podcast, my website, and my weekly newsletter all focus on the goal of translating the science of longevity into something accessible for everyone. Our goal is to provide the best content in health and wellness, and we've established a great team of analysts to make this happen. It is extremely important to me to provide all of this content without relying on paid ads. To do this, our work is made entirely possible by our members, and in return, we offer exclusive member-only content and benefits above and beyond what is available for free.
Starting point is 00:00:46
If you want to take your knowledge of this space to the next level, it's our goal to ensure members get back much more than the price of a subscription. If you want to learn more about the benefits of our premium membership, head over to PeterAtiyaMD.com forward slash subscribe. My guest this week is Isaac Kohane, who goes by Zach. Zach is a physician scientist and chair of the Department of Biomedical Informatics at Harvard Medical School, and he's an associate professor of medicine at the Brigham and Women's Hospital.
Starting point is 00:01:17
Zach has published several hundred papers in the medical literature and authored the widely used books Microarrays for Integrative Genomics and the AI Revolution in Medicine, GPT-4 and Beyond. He is also the editor-in-chief of the newly launched New England Journal of Medicine AI. In this episode, we talk about the evolution of AI. It wasn't really clear to me until we did this interview that we're really in the third generation of AI and Zach has been a part of both the second and obviously the current generation. We talk about AI's abilities to impact medicine today. In other words, where is it having an impact and where will it have an impact in the near term? What seems very
Starting point is 00:01:54
likely and of course we talk about what the future can hold. And obviously here you're starting to think a little bit about the difference between science fiction and potentially where we hope it could go. Very interesting podcast for me, really a topic I know so little about which tend to be some of my favorite episodes. Without further delay, please enjoy my conversation with Zach Cohen. Well, Zach, thank you so much for joining me today. This is a topic that's highly relevant and one that I've wanted to talk about for some time, but wasn't sure who to speak with. We eventually found our way to you. Again, thanks for making the time and sharing your expertise. Give folks a little bit of a sense of your background. What was your path
Starting point is 00:02:37
through medical school and training? It was not a very typical path. No. What happened was I grew up in Switzerland. Nobody in my family was a doctor. Come to United States, decide to major in biology, and then I get nerd sniped by computing back in the 70s, in the late 70s, and so I minor in computer science, but I still complete my degree in biology, and I go to medical school.
Starting point is 00:03:05
And then in the middle of medical school's first year, I realized, holy smokes, this is not what I expected. It's a noble profession, but it's not a science. It's an art. It's not a science. And I thought I was going into science. And so I bail out for a while to do a PhD in computer science. And this is during the 1980s now, early 1980s. And it's a heyday of AI.
Starting point is 00:03:30
It's actually second heyday. We're going through the third heyday. And it was a time of great promise. And with the retrospective scope, very clear that it was not going to be successful. There was a lot of over-promising. There is today. But unlike today, we had not released it to the public. It was not actually working in the way
Starting point is 00:03:52
that we thought it was going to work. And it certainly didn't scale. It was a very interesting period. And my thesis advisor, Peter Solovich, a professor at MIT, said, Zach, you should finish your clinical training because I'm not getting a lot of respect from clinicians. And so to bring rational decision making to the clinic, you really want to finish your clinical training.
Starting point is 00:04:17
And so I finished medical school, did a residency in pediatrics and then pediatric endocrinology, which was actually extremely enjoyable. But when I was done, I restarted my research in computing, started a lab at Children's Hospital in Boston, and then a center of biomedical informatics at the medical school. Like in almost every other endeavor, getting money gets attention from the powers that be. And so I was getting a lot of grants. And so they asked me to start the center and then eventually a new department of
Starting point is 00:04:52
biomedical informatics that I'm the chair of. We have now 16 professors or assistant professors of biomedical informatics. Then I had been involved in a lot of machine learning projects. But like everybody else, I was taken by surprise, except perhaps a little bit earlier than most. By large language models, I got a call from Peter Lee in October 22. And actually, I didn't get a call. It was an email right out of a Michael Crichton novel. It said, Zach, if you'll answer the phone, I can't tell you what it's about, but
Starting point is 00:05:25
it'd be well worth your while. And so I get a call from Peter Lee and I knew him from before. He was a professor of computer science at CMU and also department chair there. And then he went to ARPA and then he went to Microsoft. And he tells me about GPT-4. And this was before any of us had heard about chat GPT, which is initially GPT-3.5. He tells me about GPT-4. And he gets me early access to it when no one else knows that exists.
Starting point is 00:05:54
Only a few people do. And I start trying it against hard cases. I get called down. I just remember from my training, I get called down to the nursery. There's a child with a small phallus and a hole at the base of the phallus and they can't palpate testicles. And they want to know what to do because I'm a pediatric endocrinologist. And so I asked GPT-4, what would you do?
Starting point is 00:06:21
What are you thinking about? And it runs me through the whole workup of these very rare cases of ambiguous genitalia. In this case, it was congenital adrenal hyperplasia, where the making of excess androgens during pregnancy, and then subsequently in birth causes the clitoris to swell from the glands of the penis of the phallus and the labia minora to fuse to form the shaft of the, what looks like a penis, but there's no testicles. There's ovaries. And so there's a whole endocrine workup with genetic tests, hormonal tests, ultrasound, and it does it all. And it blows my mind.
Starting point is 00:07:08
It really blows my mind because very few of us in computer science really thought that these large language models would scale up the way they do. It was just not expected. And talking to Bill Gates about this, after Peter Leah introduced me to the problem, and he told me that his line engineers, in Microsoft research, a lot of his fanciest computer scientists did not expect this,
Starting point is 00:07:33
but the line engineers at Microsoft were just watching the scale up, you know, GPT-01-2, and they just saw it was gonna keep on scaling up with the size of the data and with the size of the model. And they said, yeah, of course it's going to achieve this kind of expertise. But the rest of us, I think because we value our own intellects so much, we couldn't imagine how we would get that kind of conversational expertise just by scaling up the model and the
Starting point is 00:08:04
data set. Well, Zach, that's actually kind of a perfect introduction to how I want to think about this today, which is to say, look, there's nobody listening to us who hasn't heard the term AI, and yet virtually no one really understands what is going on. So, if we want to talk about how AI can change medicine, I think we have to first invest some serious bandwidth in understanding AI. Now, you alluded to the fact that when you were doing your PhD in the early 80s, you were in the second generation of AI, which leads me to assume that the first generation was shortly following World War II and that's probably why someone by the name of Alan Turing has his name on something called the Turing Test.
Starting point is 00:08:45
Maybe you can talk us through what Alan Turing posited, what the Turing Test was and proposed to be and really what Gen 1 AI was. We don't have to spend too much time on it, but clearly it didn't work. Let's maybe talk a little bit about the postulates around it and what it was. After World War II, we had computing machines. And anybody who was a serious computer scientist could see that you could have these processes that could generate other processes. And you could see how these processes could take inputs
Starting point is 00:09:20
and become more sophisticated. And as a result, shortly after World War II, we actually had artificial neural networks, the perceptron, which was modeled, roughly speaking, on the ideas of a neuron that could take inputs from the environment and then have certain expectations. And if you updated the neuron as to what was going on, it would update the weights going into that artificial neuron. And so going back to Turing, he just came up with a test that said, essentially, if a computational entity could maintain,
Starting point is 00:10:08
essentially, its side of the conversation without revealing that it was a computer and that others would mistake it for a human, then for all intents and purposes, that would be intelligent behavior. And there's been all sorts of additional constraints put on it. And one of the hallmarks of AI, frankly, is that it keeps on moving the goalposts of what we consider to be intelligent behavior. If you had told someone in the 60s that the world chess masters were going to be beaten by a computer program.
Starting point is 00:10:46
They say, well, that's AI. Really, that's AI. And then when Kasparov was beaten by the blue, by the IBM machine, people said, well, it's just doing search very well. It's searching through all the possible moves in the future. It also has knows all the grand master moves. It has a huge encyclopedia store of all the different grand master moves. And this is not really intelligent behavior. If you told people it could recognize human faces and find your grandmother in a picture on any picture in the internet, they'd say, well, that's intelligence. And of course, when we did it, no, that was not intelligent.
Starting point is 00:11:25
And then when we said it could write a rap poem about Peter Atia based on your web page, and it did that, well, that would be intelligent. That would be creative. But then if you said it's doing it based on having created a computational model based on all the text ever generated by human beings, as much as we can gather, which is one to six terabytes of data.
Starting point is 00:11:54
And this computational model, basically it's predicting what is the next word. That's going to be saying not just the next word, but of the millions of words that could be, what are the probabilities of that next word? That is what's generating that rap. There's people who are arguing that's not intelligence. So the goal posts around the Turing test keep getting moved. So I just have to say that I no longer find that an interesting topic because it's what it's actually doing. And whether you want to call it intelligent or not, that's up to you. It's like discussing whether is a dog intelligent? Is a baby intelligent before it can recognize constancy of objects?
Starting point is 00:12:35
Initially babies, if you hide something from it, it's gone. And it comes back, it's a surprise. But at some point early on, they learn there's constancy of objects even when they don't see them. There's this spectrum of intelligent behavior. And I just like to remind myself that there's a very simple computational model of predicting the next word called a Markov model. And several years ago, people were studying songbirds, and they were able to predict the full song, the next note,
Starting point is 00:13:09
and the next note of the songbird, just using a very simple mark of model. So from that perspective, I know we think that we're all very smart, but the fact that you and I, without thinking too hard about, can come up with fluid speech. Okay, so the model is now a trillion parameters. It's not a simple Markov model, but it's still a model.
Starting point is 00:13:30
And perhaps later we'll talk about how this plays into, unfortunately, the late Kahneman's notions of thinking fast and thinking slow, and his notion of system one, which is this sort of pattern recognition, which is very much similar to what I think we're seeing here. And system two, which is the more deliberate and much more conscious kind of thinking that we pride ourselves on. But a lot of what we do is this sort of reflexive, very fast pattern recognition.
Starting point is 00:13:58
So if we go back to World War II, that's to your point where we saw basically rule-based computing come of age. Anybody who's gone back and watched movies about the Manhattan Project or the decoding of all the sorts of things took place, Enigma, for example. Again, that's straight rules-based computational power and we're obviously at the limits of, I can only go so far. It seems that there was a long hiatus before we went from there to kind of like maybe what some have called context-based computation, what your Siri does or Alexa, which is a step quite beyond that. Then of course,
Starting point is 00:14:42
you would go from there to what you've already talked about, Blue or Watson, where you have computers that are probably going even one step further. Then of course, where we are now, which is GPT-4. I want to talk a little bit about the computational side of that. More what I want to get at is this idea that there seems to be a very non-linear pace at which this is happening. I hear your point. I'd never thought of it that way. I hear your point about the goalpost moving, but I think your instinct around majoring in the right thing is also relevant, which is let's focus less on the fact that we're never quite hitting the asymptote definitionally. Let's look at the actual output and it is staggeringly different. What was it that was taking place during the period of your PhD, what you're calling wave
Starting point is 00:15:34
two of AI? What was the objective and where was the failure? The objective was in the first era, you wrote computer programs in assembler language or in languages like Fortran. And there was a limit of what you could do. You had to be a real computational programmer to do something in that mode. In wave two, in the 1970s, we came up with these rule-based systems where we said rules in what looked like English. If there is a patient who has a fever and you get an isolate from the lab and that bacteria
Starting point is 00:16:13
in the isolate is gram positive, then you might have a streptococcal infection with a probability of so-and-so. And these rule-based systems, which you're now programming in the level of human knowledge, not in computer code, the problem with that was several-fold. A, you're going to generate tens of thousands of these rules, and these rules would interact in ways that you could not anticipate. And we did not know enough, and we could not pull out of human beings the right probabilities. And what is the right probability of you have a fever and you don't see anything on the blood test?
Starting point is 00:16:53
What else is going on? And there's a large set of possibilities and getting all those rules out of human beings ended up being extremely expensive and the results were not stable. And for that reason, because we didn't have much data online, we could not go to the next step, which is have data to actually drive these models. What were the data sources then? Books, textbooks and journals as interpreted by human experts. That's why some of these were called expert systems,
Starting point is 00:17:30
because they were derived from introspection by experts who would then come up with the rules, with the probabilities. And some of the early work, like for example, there was a program called MISON run by Ted Shortliffe out of Stanford, who developed a antibiotic advisor that was a set of rules based on what he and his colleagues sussed out from the different infectious disease textbooks and infectious disease experts. And it stayed only up to date as long as they kept on looking at the literature, adding rules, fine tuning it. There's an interaction between two rules that was not desirable. Then you had to adjust that.
Starting point is 00:18:10
Very labor intensive. And then if there's a new thing, you'd have to add some new rules. If AIDS happened, you'd have to say, oh, there's this new pathogen. I have to make a bunch of rules. The probability is gonna be different if you're an IV drug abuser or if you're a male homosexual. And so it was very, very hard to keep up. And in fact, people didn't.
Starting point is 00:18:34
What was the language that it was programmed in? Was this Fortran? No, no, these were so-called rule-based systems. And so the languages, for example, system mycin was called e-mison, essential myson. So these looked like English. Super labor intensive. Super labor intensive.
Starting point is 00:18:51
And there's no way you could keep it up to date. And at that time, there was no electronic medical records. They were all paper records. So not informed by what was going on in the clinic. Three revolutions had to happen in order for us to have what we have today. That's why I think we had such a quantum jump recently. Before we get to that, that's the exciting question, but I just want to go back to the gen two. Were there other industries that were having more success than medicine? Were there applications in the military? Were there applications elsewhere in government where they got a little closer to utility?
Starting point is 00:19:28
Yes. So there's a company which was a remnant of a... Back in the 1970s, there were a whole bunch of computer companies around what we called 128 in Boston. And these were companies that were famous back then, like Wang Computer, like Digital Equipment Corporation. And it's a very sad story for Boston because that was before Silicon Valley got its pearl of computer companies around it. And one of the companies, Digital Equipment Corporation, built a program called R1.
Starting point is 00:20:01
And R1 was an expert in configuring the mini computers that you ordered. So you wanted some capabilities and it would actually configure all the industrial components, the processors, the disk and it would know about all the exceptions and what you needed to know, what cabling, what memory configuration, all that was done. And it basically replaced several individuals who had that very, very rare knowledge to configure their systems. It was also used in several government logistics efforts. But even those efforts, although they were successful and used commercially, were limited
Starting point is 00:20:41
because it turns out human beings, once you got to about three, four, five, six thousand rules, no single human being could keep track of all the ways these rules could work. We used to call this the complexity barrier, that these rules would interact in unexpected ways and you'd get incorrect answers, things that were not commonsensical because you'd get incorrect answers, things that were not commonsensical, because you had actually not captured everything about the real world. And so it was very narrowly focused. And if the expertise was a little bit outside the area of focus,
Starting point is 00:21:18
if, let's say, it was an infectious disease program, and there was a little bit of influence from the cardiac status of the patient. And you had not accurately modeled that. Its performance would degrade rapidly. Similarly, if there was in digital equipment a new model that had a complete different part that had not included and that there were some dependencies that were not modeled, it would degrade in performance.
Starting point is 00:21:46
So these systems were very brittle, did not show common sense. They had expert behavior, but it was very narrowly done. There were applications of medicine back then that survived till today. For example, already back then we had these systems doing interpretation of ECGs pretty competently, at least a first pass until they would be reviewed by an expert cardiologist.
Starting point is 00:22:12
There's also a program that interpreted what's called serum protein electrophoresis, where you look at a protein separated out by an electric gradient to make a diagnosis, let's say of myeloma or other protein disorders. And those also were deployed clinically, but they only worked very much in narrow areas. They were by no stretch of imagination, general purpose, reasoning machines. So let's get back to the three things. There are three things that have taken the relative failures of first and second attempts at AI and got us to where we are today. I can guess what they are, but let's just have you walk us through them. The first one was just lots of data.
Starting point is 00:22:57
We needed to have a lot of online data to be able to develop models of interesting performance and quality. So ImageNet was one of the first such data sets, collections of millions of images with annotations, importantly. This has a cat in it, this has a dog in it, this is a blueberry muffin, this has a human in it. And having that was absolutely essential to allow us to train the first very successful neural network models. And so having those large data sets was extremely important.
Starting point is 00:23:37
The other, and there's equivalent in medicine, which is we did not have a lot of textual information about medicine until PubMed went online. So all the literature, medical literature, at least we have an abstract of it in PubMed, plus we have for a subset of it that's open access because the government has paid for it through grants. There's something called PubMed Central, which has the full text. So all of a sudden that has opened up over the last 10 years. And then electronic health records, after Obama signed the High Tech Act, electronic health records, which also ruined the lives of many doctors,
Starting point is 00:24:18
also happened to also generate a lot of text for the use in these systems. So that's large amounts of data being generated online. The second was the neural network models themselves. So the perceptron that I mentioned that was developed not too long after World War II was shown by one of the pioneers of AI, Marvin Minsky, to have fundamental limitations in that it could not do certain mathematical functions like what's called an exclusive or gate.
Starting point is 00:24:49
Because of that, people said these neural networks are not going to scale. But there were a few true believers who kept on pushing and making more and more advanced architectures and those multi-level deep neural networks. So instead of having one neural network, we layer on top of one neural network, another one and another one and another one so that the output of the first layer gets propagated up to the second layer of neurons to the third layer and fourth layer and so on. And I'm sorry, was this a theoretical mathematical breakthrough or a technological breakthrough? Both. It was both because having those insights that these, we could actually come up with
Starting point is 00:25:33
all the mathematical functions that we needed to, we could simulate them with these multilevel networks where it was a theoretical insight, but we never made anything out of it if not for the fact of sweaty teenagers, mostly teenage boys playing video games. In order to have first person shooters capable of running high resolution pictures of aliens or monsters in high resolution 24 bit color, 60 frames per second, we needed to have processors, very parallel processors that would allow you to do the linear algebra that allow you to calculate what was going to be the intensity of color on every dot of the screen at 60 frames per second. And that's literally just because of the matrix multiplication
Starting point is 00:26:25
math that's required to do this. You have the n by m matrices that are so big and you're crossing and dotting huge matrices. Huge matrices. And it turns out that's something that can be run in parallel. So you want to have multiple parallel processors capable of rendering those images again at 60 frames per second.
Starting point is 00:26:47
So basically millions of bits on your screen being rendered at 24 or 32 bit color. And in order to do that, you need to have that linear algebra that you just referred to being run in parallel. And so these parallel processors called graphical processing units, GPUs, were developed. And the GPUs were developed by several companies, and some of them stayed in business, some didn't, but they were aptly essential to the success of video games. Now, it then occurred to many smart mathematicians and computer scientists that the same linear algebra that was used to drive that computation for images could also be used to calculate the weights of the edges between the neurons in a neural network.
Starting point is 00:27:42
So the mathematics of updating the weights in response to stimuli, let's say of a neural network, updating of those weights can be done all in linear algebra. And if you have this processor, so a typical computer has a central processing unit. So that's one processing unit. A GPU has tens of thousands of processors that do this one very simple thing, linear algebra. And so by having this parallelism that only supercomputers would have typically on your simple PC, because you needed to show the graphics at 60 frames per second, gave us all of a sudden these commodity chips that allowed
Starting point is 00:28:25
us to calculate the performance of these multi-level neural networks. So that theoretical breakthrough was the second part, but would not have happened without the actual implementation capability that we had with the GPUs. And so Nvidia would be the most successful example of this, presumably? It was not the first, but it's definitely the most successful example. And there's a variety of reasons why it was successful and created an ecosystem of implementers
Starting point is 00:28:54
who built their neural network deep learning systems on top of the Nvidia architecture. Would you go back and look at the calendar and say this was the year or quarter when there was escape velocity achieved there? Yeah, so it's probably around 2012 when there was an ongoing contest every year saying who has the best image recognition software.
Starting point is 00:29:19
And these deep neural networks running off GPUs were able to outperform significantly all their other competitors in image recognition in 2012. That's very clearly when everybody just woke up and said, Whoa, we knew about neural networks, we didn't realize that these convolutional neural networks were going to be this effective. And it seems that the only thing that's going to stop us is computational speed and the size of our data sets that moved the things very fast along in the imaging
Starting point is 00:29:56
space with very soon consequences in medicine. It was only six years later that we saw journal articles about recognition of retinopathy, diseases affecting the retina, the back of your eye in diabetes. And a paper coming out of all places from Google saying we can recognize different stages of retinopathy based on the images of the back of the eye. And that also was a wake up call because yes, part of the goalpost moving is great that we could recognize cats and dogs in web pages. But now all of a sudden, this thing that we thought was specialized human
Starting point is 00:30:37
expertise could be done by that same stack of software. Just if you gave it enough cases of these retinopathy's it would actually work well and furthermore what was wild was that there's something called transfer learning where you tune up these networks given to recognize cats and dogs and in the process of recognizing cats and dogs it learns how to recognize little circles and lines and fuzziness and so on. You did a lot better in training up the neural network first on the entire set of images and then on the retinas. And if you just went straight to,
Starting point is 00:31:16
I'm just going to train on the retinas. And so that transfer alerting was impressive. And then the other thing as a doctor was impressive to many of us. I was actually asked to write an editorial for the journal of the American and medical association in 2018, when a Google article was written. What was impressive to us was that what was the main role of doctors in that publication? It was just twofold. One was to just label the images that were used for training.
Starting point is 00:31:44
This is retinopathy is not retinopathy. twofold. One was to just label the images that were used for training. This is retinopathy, it's not retinopathy. And then to serve as judges of its performance. And that was it. The rest of it was computer scientists working with GPUs and images tuning it. And that was it. Didn't look anything like medical school and you were having expert level recognition of retinopathy. That was a. It didn't look anything like medical school. And you were having expert level recognition of retinopathy. That was a wake up call. You've alluded to the 2017 paper by Google.
Starting point is 00:32:14
Attention is all that is needed. I think is the title of the paper. Attention is all you need. That's not what I'm referring to. I'm also referring to that. A 2018 paper in JAMA. I'm sorry. You're talking about the great paper, attention is all you need. That was about the invention of the transformer, which is a specific type of neural network architecture. I was talking about these were vanilla, fairly vanilla convolutional neural networks, the
Starting point is 00:32:39
same one that can detect dogs and cats. It was a big medical application, retinopathy 2018. Except for computer scientists, no one noticed the attention is all you need paper. And Google had this wonderful paper that said, you know, if we recognize not just text that collocates together, because previously, so we're gonna get away from images for a second. There was this notion that I can recognize a lot of similarities in text. If I see which words occur together, I can implicate the meaning of a word by the company it keeps. And so, if I see
Starting point is 00:33:25
And so if I see this word and it has around it, kingdom, crown, throne, it's about a king. And similarly for queen and so on. That kind of association in which we created what was called embedding vectors, which just in plain English, it's a string of numbers that says for any given word, what's the probability? How often do these other words co-occur with it? And just using those embeddings, those vectors, those lists of numbers that describe the co-occurrence
Starting point is 00:33:58
of other words, we were able to do a lot of what's called natural language processing, which looking at text and saying, this is what it means. This is what's going on. But then in the 2017 paper, they actually took a next step, which was the insight that where exactly the thing that you're focusing on was in a sentence, what was before and after the actual ordering of it mattered, not just the simple co-occurrence that knowing what position that word was in the sentence actually made a difference. That paper showed the performance went way up in terms of recognition. And that transformer architecture that came from that paper made it clear for number of researchers, not me, that if you scaled that transformer architecture up to
Starting point is 00:34:53
a larger model, so that the position dependence and this vector was learned across many, many more texts, the whole internet, you could train it to do various tasks. This transformer model, which is called the pre-trained model. So I apologize. I find it very boring to talk about because unless I'm working with fellow nerds, this transformer, this pre-trained model, to think of it as the equivalent of an equation with multiple variables.
Starting point is 00:35:23
In the case of GPT-4, we think it's about a trillion variables. It's like an equation where you have a number in front of each variable, a coefficient that's about a trillion long. And this model can be used for various purposes. One is the chatbot purpose, which is given this sequence of words, what is the next word that's going to be said? Now that's not the only thing you could use this model for, but that's turns out to have been the breakthrough application of the transformer model for text. Just to round out what you said earlier, Zach, would you say that is the third thing that enabled this third wave of AI, the transformer? It was not what I was thinking about.
Starting point is 00:36:07
For me, I was thinking of the real breakthrough in data-driven AI I put around the 2012 era. This is yet another. If you talk to me in 2018, I would have already told you we're in a new heyday and everybody would agree with you. There was a lot of excitement about AI just because of image recognition capabilities. This was an additional capability that's beyond what many of us were expecting just from the scale up of the neural network. The three, just to make sure I'm consistent, was large data sets, multi-level neural networks, aka deep neural networks, and the GPU infrastructure.
Starting point is 00:36:47
That brought us well through the 2012 to 2018. The 2017 blip that became what we now know to be this whole large language model transformer architecture, that development, unanticipated for many of us, but that was already on the heels of a Ascendant AI era, there was already billions of dollars of frothy investment in frothy companies, some of which did well and many of which did not do so well. The transformer architecture has revolutionized many parts of the human condition, I think, but it was already part of it, I think, the third wave.
Starting point is 00:37:31
There's something about GPT where I feel like most people by the time GPT-3 came out, or certainly by 3.5, this was now outside of the purview of computer scientists, people in the industry who were investing in it. This was now becoming as much a verb as Google was in probably the early 2000s. There were clearly people who knew what Google was in 96 and 97, but by 2000, everybody knew what Google was, right? Something about GPT 3.5 or 4 was kind of the tipping point where I don't think you cannot know what it is at this point. I don't know if that's relevant to the story, meaning does that sort of speak to what trajectory we're on now? The other thing that I think, Zach, has become so audible in the past year is the elevation
Starting point is 00:38:28
in the discussion of how to regulate this thing, which seems like something you would only argue about if you felt that there were a chance for this thing to be harmful to us in some way that we do not yet perceive. What can you say about that? Because that's obviously a nod to the technical evolution of AI that very serious people are having discussions about pausing moratoriums, regulations. There was no public discussion of that in the 80s, which may have spoke to the fact that in the 80s, it just wasn't powerful enough to pose a threat. Can you maybe give us a sense of what people are debating now? What is the smart, sensible, reasonable argument on both sides of this? Let's just have you decide what the two sides are. I'm assuming one side says,
Starting point is 00:39:21
pedal to the metal. Let's go forth on development. Don't regulate this. Let's just go nuts. The other side is, no, we need to have some breaks and barriers. Not quite that. So you're absolutely right that chat bots have now become a commonly used noun. And that probably happened with the emergence of GPT 3.5. And that appeared around, I think, December of 2022.
Starting point is 00:39:44
But now, yes,, December of 2022. But now, yes, because out of the box, that pre-trained model I told you about could tell you things like, how do I kill myself? How do I manufacture a toxin? It could allow you to do a lot of harmful things. So there was that level of concern. We can talk about what's been done about those first order efforts. Then there's been a group of scientists who interestingly went from saying,
Starting point is 00:40:14
we'll never actually get general intelligence from this particular architecture, to saying, oh my gosh, this technology is able to influence in a way that I had not anticipated. And now I'm so worried that either because it's malevolent or just because it's trying to do something that has bad side effects for humanity, it presents an existential threat. Now on the other side, I don't believe is anybody saying, let's just go heads down and let's see how fast we can get to artificial general intelligence. Or if they do think that, they're not saying it openly.
Starting point is 00:40:54
Can you just define AGI, Zach? I think we've all heard the term, but is there a quasi accepted definition? First of all, there's not, and I hate myself for even bringing it up because it starts. I was going to bring it up before you anyway. It was inevitable. That was an unfortunate slip because artificial general intelligence means a lot of things to a lot of people and I slipped because I think it's again a moving target and it's very much eye on the boulder. There's a guy called Eliaz Yudkowsowski, one of the so-called Doomers, and he comes up with great scenarios of how a sufficiently intelligent system could figure out how to persuade human beings to do bad things
Starting point is 00:41:36
or control of our infrastructure to bring down our communications infrastructure or airplanes out of the sky. And we can talk about whether that's relevant or not. And on the other side, we have, let's say, OpenAI and Google. But what's fascinating to me is that OpenAI, which, working with Microsoft, generated GPT-4, were not saying publicly at all, let's not regulate it. In fact, they were saying, please regulate me. Sam Altman went on a world tour where he said, they were saying, please regulate me.
Starting point is 00:42:05
Sam Altman went on a world tour where he said, we should be very concerned about this. We should regulate AI. And he was before Congress saying we should regulate AI. And so I feel a bit churlish about saying this because Sam was kind enough to write forward to the book I wrote with Peter Lee and Kerry Goldberg on GPT-4 and the revolution in medicine. But I was wondering why were they insisting so much on regulation? And there's two interpretations.
Starting point is 00:42:34
One is just a sincere, and it could very well be that sincere wish that it be regulated. So we check these machines, these programs to make sure they don't actually do anything harmful. The other possibility, unfortunately, is something called regulatory lock-in, which means I'm a very well-funded company and we're going to create regulations with Congress about what is required, which boxes do you have to check in order to be allowed to run. If you're a small company, you're not going to have a bevy of lawyers with big checks to comply with all the regulatory requirements. And so I think Sam is, I don't know him personally, I imagine he's a very well motivated individual,
Starting point is 00:43:17
but whether it's for the reason of regulatory lock-in or for genuine concern, there has not been any statements of, let's go heads down. They do say, let's be regulated. Now, having said that, before you even go with a doomer scenario, I think there are someone just as potentially evil that we have to worry about, another intelligence, and that's human beings. And how do human beings use these great tools? human beings and how do human beings use these great tools. So just as we know for a fact that one of the earliest users of GPD 4 were high schoolers trying to do their homework
Starting point is 00:43:54
and solve hard puzzles given to them, we also know that various parties have been using the amazing text generation and interactive capabilities of these programs to spread misinformation, to chat bots. And there's a variety of line things that could be done by third parties using these engines. And I think that's for me the clear and present danger today, which is how do individuals decide to use these general purpose programs.
Starting point is 00:44:27
If you look at what's going on in the Ukraine-Russian war, I see more and more autonomous drones with greater and greater autonomous capabilities. Those are purpose-built to actually do dangerous things. And a lot of science fiction fans will refer to Skynet from the Terminator series, but we're literally building it right now. In the Terminator, Zach, they kind of refer to a moment, I don't remember the year, like 1997 or something. I think they talk about how Skynet became, quote, self-aware. Somehow, when it became self-aware, it just decided to destroy humans. Is self-aware movie speak for AGI? What do you think self-aware means in more technical terms? Or is it super intelligence? There's so many terms here and I don't know
Starting point is 00:45:32
what they mean. Okay. Self-awareness means a process by which the intelligent entity can look back, look inwardly at its own processes and recognize itself. Now that's very hand wavy, but Douglas Hofster has probably done the most thoughtful and clear writing about what self-awareness means. I will not do it justice, but if you really want to read a wonderful book that spends a whole book trying to explain it, it's called, Am A Strange Loop. And in I Am A Strange Loop, he explains how if you have enough processing power and you can represent the processes that you have essentially models of
Starting point is 00:46:19
the processes that constitute you. In other words, you're able to look at what you're thinking, you may have some sense of self-awareness. There's a bit of an act of faith on that. Many AI researchers don't buy that definition. There's a difference between self-awareness and actual raw intelligence. You can imagine a super powerful computer that would predict everything
Starting point is 00:46:43
that was gonna happen around you and was not aware of itself as an entity. The fact remains, you do need to have a minimal level of intelligence to be able to be self-aware. So a fly may not be self-aware. It just goes and finds good smelling poop and does whatever it's programmed to do on that. But dogs have some self-awareness and awareness of their surroundings. They don't have perfect self-awareness. They don't recognize themselves in the mirror and they'll bark at that.
Starting point is 00:47:17
Birds will recognize themselves in mirrors. We recognize ourselves in many, many ways. So there is some correlation between intelligence and self-awareness, but these are not necessarily dependent functions. So what I'm hearing you say is, look, there are clear and present dangers associated with current best AI tools in that humans can use them for nefarious purposes. It seems to me that the most scalable example of that is still relatively small in that it's not existential threat to our species large, correct? Well, yes and no. If I was trying to do gain of
Starting point is 00:47:55
function research with a virus, I could use these tools very effectively. Yeah, that's a great example. There's this disconnect and perhaps you understand the disconnect better than I do, there's those real existential threats. And then there's this more fuzzy thing that we're worried about correctly, about bias, incorrect decisions, hallucinations. We can get into what that might be and our use in the every day of human condition. And there's concerns about mistakes that might be made. There's concerns about displacement of workers that just as automation displaced a whole
Starting point is 00:48:36
other series of workers, now that we have something that works in the knowledge industry automatically, just as we're placing a lot of copy editors and illustrators with AI, where's that going to stop? It's now much more in the white collar space. And so there is concern around the harm that could be generated there. In the medical domain, are we getting good advice? Are we getting bad advice whose interests are being optimized in these various decision procedures? That's another level that doesn't quite rise at all to the level of extinction events,
Starting point is 00:49:11
but a lot of policymakers and the public seem to be concerned about it. Those are fair points. Let's now talk about that state of play within medicine. So I liked your first example, almost one we take for granted, but you go and get an EKG at the doctor's office. This was true 30 years ago, just as it is today. You get a pretty darn good readout. It's going to tell you if you have an AV block, it's going to tell you if you have a bundle
Starting point is 00:49:35
branch block, but in this way, they read EKGs better than I do. That's not saying much anymore, but they do. What was the next area where we could see this? It seems to me that radiology is a field of medicine, which is of course, image pixel based medicine, that would be the most logical next place to see AI do good work. What is the current state of AI in radiology? In all the visual-based medical specialties, it looks like AI can do as well as many experts. So what are the image appreciation subspecialties? Pathology, when you're looking at slices of tissue
Starting point is 00:50:20
under the microscope. Radiology, where you're looking at x-rays or MRIs, dermatology, where you're looking at pictures of the skin. So in all those visual-based specialties, the computer programs are doing by themselves as well as many experts, but they're not replacing the doctors because that image recognition process is only part of their job. Now, to be fair to your point in radiology, we already today before AI in many hospitals would send X-rays by satellite to Australia or India where they would be read
Starting point is 00:51:06
overnight by a doctor or a specially trained person who had never seen the patient. And then the reports filed back to us because they're 12 hours away from us overnight would have the results of those reads. And that same kind of function can be done automatically by AI. So that's replacing a certain kind of doctor. Let me dig into that a little bit more. So let's start with a relatively simple type of image such as a mammogram or a chest x-ray. So it's a single image.
Starting point is 00:51:34
I mean, I guess with a chest x-ray, you'll get an AP and a lateral, but let's just say you're looking at an AP or a single mammogram. A radiologist will look at that. A radiologist will have clinical information as well. So they will know why this patient presented in the case of the chest x-ray, for example, in the ER in the middle of the night. Were they short of breath? Do they have a fever?
Starting point is 00:51:58
Do they have a previous x-ray? I can compare it to all sorts of information. Are we not at the point now where all of that information could be given to the AI to enhance the pre-test probability of whatever diagnosis it comes to? I am delighted when you say pre-test probability. Don't talk dirty around me. Love my Bayes theorem over here. Yep. So you just said a lot because what you just said actually went beyond what the straight
Starting point is 00:52:26
convolutional neural network would do because they actually could not replace radiologists because they could not do a good job of taking into account the previous history of the patient. And it's required the emergence of transformers where you can have multimodality of both the image and the text. Now they're going to do better than many, many radiologists today. There is, I don't think any threat yet to radiologists as a job. One of the most irritating to doctors predictions was by Jeffrey Hinton, one of the intellectuals leaders of neural network architecture.
Starting point is 00:53:04
He said, I think it was in 2016, I have this approximately wrong, but in six years we wouldn't have no need for radiologists. And that was just clearly wrong. And the reason it was wrong is A, they did not have these capabilities that we just talked about, about understanding about the clinical context. But it's also the fact that we just don't have enough radiologists. Meaning to do the training? To actually do the work.
Starting point is 00:53:29
So if you look at American medicine, I'll let you shut me down, but if you look at residency programs, we're not getting enough radiologists out. We have an overabundance of applicants for interventional radiology. They're making a lot of money. It's high prestige, but straight up radiology readers, not enough of them. Primary care doctors, I go around medical schools and ask who's becoming a primary
Starting point is 00:53:56
care doctor. Almost nobody. So, primary care is disappearing in the United States. In fact, Mass General and Brigham announced officially they're not seeing primary care patients. People are still going to dermatology and they're still going into plastic surgery. What I did, pediatric endocrinology, half of the slots nationally are not being filled. Pediatric developmental disorders like autism,
Starting point is 00:54:21
those slots, half of them filled. PDID, there's a huge gap emerging in the available expertise. So it's not what we thought it was going to be, that we had a surplus of doctors that had to be replaced. It's just, we have a surplus in a few focused areas, which are very popular. And then for all the work of primary care and primary prevention kind of stuff that you're interested in, we have almost no doctors available.
Starting point is 00:54:50
Yeah. Let's go back to the radiologist for a second because again, I'm fixated on this one because it seems like the most, well, the closest one to address. Again, if you're saying, look, we have a dearth of imaging radiologists who are able to work the emergency rooms, urgent care clinics, and hospitals, wouldn't that be the first place we would want to apply our best of imaging recognition with our super powerful GPUs and now plug them into our transformers with our language models so that I can get clinical history, medical past history, previous images, current images, and I don't have to send it to a radiologist in Australia to read it, who then has to send it back to a radiologist here to check.
Starting point is 00:55:38
If we're just trying to fill a gap, that gap should be fillable, shouldn't it? That's exactly where it is being filled. And what keeps distracting me in this conversation is that there's a whole other group of users of these AIs that we're not talking about, which is the patients. And previously, none of these tools were available to patients. With the release of GPT 3.5 and 4, and now Gemini and Clawed 3, they're being used by patients all the time in ways that we had not anticipated.
Starting point is 00:56:09
Let me give you an example. So there's a child who was having trouble walking, having trouble chewing, and then started having intractable headaches. Mom brought him to multiple doctors, they did multiple imaging studies, no diagnosis, kept on being an intractable pain. She just typed into GPT-4 all the reports and asked GPT-4 what's the diagnosis and GPT-4 said tethered cord syndrome. She then went with all the
Starting point is 00:56:40
imaging studies to a neurosurgeon and said, what is this? He looked at it and said, tethered core syndrome. And we have such an epidemic of misdiagnosis and undiagnosed patients. Part of my background that I'll just mention briefly, I'm the principal investigator of the coordinating center of something called the Undiagnosed Network. It's a network with 12 academic hospitals down the West Coast from University of Washington, Stanford, UCLA, Baylor, up the East Coast, Harvard hospitals, NIH. And we see a few thousand patients every year. And these are patients who have been undiagnosed and they're in pain. That's just a small fraction of those who are undiagnosed. And yes, we bring to bear
Starting point is 00:57:21
a whole bunch of computational techniques and genomic sequencing to actually be able to help these individuals. But it's very clear that there's a much larger burden out there of misdiagnosed individuals. But the question for you, Zach, which is, does it surprise you that in that example, the mother was the one that went to GPT-4 and inputted that? I mean, she had presumably been to many physicians along the way. Were you surprised that one of the physicians along the way hadn't been the one to say, gee, I don't know, but let's see what this GPT-4 thing can do?
Starting point is 00:57:55
Most clinicians I know do not have what I used to call the Google reflex. I remember when I was on the wards and we had a child with dysmorphology, they look different. And I said to the fellows, this is after residency, what is the diagnosis? And they said, I don't know, I don't know. I said, he has this and this and this finding, what's the diagnosis? And I said, how would you find out? They had no idea. And I just said, let's take what I just said and type it into Google. In the top three responses, there was the diagnosis. And that reflex, which they do use in a civilian life, they did not have in the clinic. And doctors are in a very unhappy position these days. They're really being driven very, very hard.
Starting point is 00:58:42
And they're being told to use certain technological tools. They're being turned into data entry clerks. They don't have the Google reflex. They don't have the reflex, who has the time to look up a journal article? They don't do the Google reflex. Even less do they have the, let's look at the patient's history and see what GPT-4 would come up with.
Starting point is 00:59:03
I was gratified to see early on doctors saying, wow, look, I just took the patient history, plugged into GPT-4 and said, write me a letter of prior authorization. And they were actually tweeting about doing this, which on the one hand I was very, very pleased for them because it was saving them five minutes to write that letter to the insurance company saying, please authorize my patient for this procedure. I was not pleased with them because if you use chat GPT, you're using a program that is covered by OpenAI as opposed to a version of GPT-4 that is being run on protected Azure cloud by Microsoft,
Starting point is 00:59:42
which is HIPAA covered. For those of you audience doesn't know, HIPAA is the legal framework under which we protect patient privacy. And if you violate it, you can be fined and even go to prison. So in other words, if a physician wants to put any information into GPT-4, they better not identify it.
Starting point is 01:00:02
That's right. So they just plunked in a patient note into chat GBT. That's a HIPAA violation. If there's a Microsoft version of it, which is HIPAA compliant, it's not. So they were using it to improve their lives. The doctors were using it for improving the business, the administrative part of healthcare,
Starting point is 01:00:18
which is incredibly important. But by and large, only a few doctors use it for diagnostic acumen. And then what about more involved radiology? So obviously a plain film is one of the more straightforward things to do, although it's far from straightforward as anybody knows who's stared at it, chest x-ray. But once we start to look at three-dimensional images, such as cross-sectional images, CT scans, MRIs, or even more complicated images
Starting point is 01:00:46
like ultrasound and things of that nature. What is the current state of the art with respect to AI in the assistance of reading these types of images? That's the very exciting news, which is, remember how I said it was important to have a lot of data, one of the three ingredients of breakthrough. So all of a sudden having a lot of data around, for example, echocardiograms, the ultrasound of your heart, normally takes a lot of training
Starting point is 01:01:14
to interpret those images correctly. So there is a recent study from the Echo Clip Group, led I think out of UCLA. And they took a million echo cardiograms and a million textual reports and essentially trained the model both to create those embeddings I talked about of the images and of the text.
Starting point is 01:01:39
Just to make sure people understand what we're talking about, this is not, here's a picture of a cat, here's a description, cat. When you put the image in, you're putting a video in. Now, you're putting a multi-dimensional video because you have time scale, you have Doppler effects. This is a very complicated video that is going in.
Starting point is 01:02:02
It's a very complicated video and it's three dimensional and it's weird views from different angles. And it's dependent on the user. In other words, the tech, the radiology tech can be good or bad. If I was the one doing it, it would be awful. The echo tech does not have medical school debt. They don't have to go to medical school. They don't have to learn calculus. They don't have to learn physical chemistry, all the hoops that you have to go through in medical school. You don't have the attitudinal debt of doctors. So in two years they get that all the skills and they actually do a pretty good job. They do a fantastic job. But my point is their skill is very much an important determinant of the quality of the image. Yes. But what we still require these days is a cardiologist to then read it and
Starting point is 01:02:49
interpret it. Right. That's sort of where I'm going by the way is we're going to get rid of the cardiologist before we get rid of the technician. We're on the same page. My target in this conversation is nurse practitioners and physician assistants with these tools can replace a lot of expert clinicians. And there is a big open question, what is the real job for doctors in 10 years from now? And I don't think we know the answer to that
Starting point is 01:03:15
because you fast forwarded the conversation just now. Excellent. Well, let's think about it. We still haven't come to proceduralists. So we still have to talk about the interventional radiologist, the interventional cardiologist, and the surgeon. We can talk about the role of the surgeon and the da Vinci robot in a moment, but I think what we're doing is we're identifying the pecking order of physicians.
Starting point is 01:03:37
Let's not even think about it through the lens of replacement. Let's start with the lens of augmentation, which is the radiologist can be the most easily augmented, the pathologist, the dermatologist, the cardiologist who's looking at ECHOs and EKGs and stress tests. People who are interpreting visual data and using visual data will be the most easily augmented. The second tranche of that will be people who are interpreting language data plus visual data. So now we're talking about your internist, your pediatrician, where you have to interpret symptoms and combine them with laboratory
Starting point is 01:04:15
values and combine it with a story and an image. Is that a fair assessment in terms of tier? Absolutely a fair assessment. My only quibble, it's not a quibble, I'm going to keep on going back to this, is in a place where we don't have primary care. The American Association of Medical Colleges estimates that by 35, that's only 11 years from now, we'll be missing on the order of 50,000 primary care doctors. As I told you, I can't get primary care at the Brigham or at MGH today. And in the absence of that, you have to ask yourself, how can we replace these absent primary care practitioners with nurse practitioners, with physician assistants
Starting point is 01:04:54
augmented by these AIs? Because there's literally no doctor to replace. So tell me, Zach, where are we technologically on that augmentation? If Nvidia never came out with another chip, if they literally said, you know what, we are only interested in building golf simulators and we're done with the progress of this and this is as good as it's going to get. Do we have good enough GPUs, good enough multilayer neural networks that all you need is more data and
Starting point is 01:05:27
training sets that we could now do the augmentation that has been described by us in the last five minutes? The short answer is yes. Let me make it very concrete. Most concierge services cost in Boston somewhere between five and $20,000 a year. You can get this very low cost of concierge service that I'm just amazed that have not done the following called One Medical. One Medical was acquired by Amazon and they have a lot of nurse practitioners in there
Starting point is 01:05:54
and you can make an appointment and you can text with them. I believe that those individuals could be helped in ordering the right imaging studies, the right EKGs, the right medications and assess your continuing heart failure and only decide in the very few cases that you need to see a specialist cardiologist or a specialist endocrinologist today. Just to be a matter of just making the current models better, evaluating them because not all models are equal. A big question for us, this is the regulatory question, which is which ones do a better job and they're not all equal.
Starting point is 01:06:36
I don't think we need technological breakthroughs to just make the current set of paraprofessionals work at the level of entry level doctors. Let me quickly say the old very bad joke. What do you call the medical student who graduates at the bottom of this class? Doctor. And so if you could just merely get the bottom 50% of doctors to be as good as the top 50%, that'll be transformative for healthcare. Now, there are other superhuman capabilities
Starting point is 01:07:09
that we can go towards, and we can talk about if we want, that do require the next generation of algorithms, Nvidia architectures, and data sets. Everything stopped now, we could already transform medicine. It's just a matter of the sweat equity to create the models, figure out how to include them in the workflow, how to pay for them, how to create a reimbursement
Starting point is 01:07:35
system and a business model that works for our society. But there's no technological barrier. In my mind, everything we've talked about is take the best case example of medicine today and augment it with AI such that you can raise everyone's level of care to that of the best, no gaps, and it's scaled out. Okay. Now let's talk about another problem, which is where do you see the potential for AI in solving problems that we can't even solve on the best day at the best hospitals with the best doctors? So let me give you an example. We can't really diagnose Alzheimer's disease
Starting point is 01:08:22
until it appears to be at a point that for all intents and purposes is irreversible. Maybe on a good day, we can halt progression really, really early in a patient with just a whiff of MCI, mild cognitive impairment, maybe with an early amyloid detection and an anti-amyloid drug. But is it science fiction to imagine that there will be a day when an AI could listen to a person's voice, watch the movements of their eyes, study the movements of their gait and predict 20 years in advance when a person is staring down the barrel of a neurodegenerative disease and act at a time when maybe we could actually reverse it. How science fiction is that? I don't believe it's science fiction at all. Do you know that looking at retinas today,
Starting point is 01:09:12
images of retina, straightforward convolutional neural network, not even ones that involve transformers, can already tell you by looking at your retina, not just whether you have retinal disease, but if you have hypertension, if you're a male, if you're female, how old you are, and some estimate of your longevity. And that's just looking at the back of your eye and seeing enough data. I was a small player in a study that appeared in Nature
Starting point is 01:09:38
in 2005 with Bruce Yankner. We were looking at frontal lobes of individuals who had died for a variety of reasons, often accidents of various ages. And we saw bad news for people like me that after age 40, your transcriptome, the genes that are switched on, fell off a cliff. 30% of your transcriptome went down. And so there seemed to be a big difference in the expression of genes around age 40, but there was one 90 year old who looked like the young guy.
Starting point is 01:10:10
So maybe there's hope for some of us. But then I thought about it afterwards and there were other things that actually have much smoother functions, which don't have quite the follow up like our skin. So our skin ages. In fact, all our organs age and they age at different rates. You're saying that the transcriptome of the skin, you did not see this cliff-like effect at a given age the way you saw it in the frontal cortex.
Starting point is 01:10:34
So different organs age at different rates, but having the right data sets, and the ability to see nuances that we don't notice, makes it very clear to me that the early detection part, no problem. It can be very straightforward. The treatment part, we can talk about it as well. But again, we had early on from the very famous Framium Heart Study, a predictor of when you had going to have heart disease based on just a handful of variables. Now we have these artificial intelligence models that based on hundreds of variables
Starting point is 01:11:10
can predict various other diseases and it will do Alzheimer's, I believe, very soon. I think you'll be able to see a combination of gait, speech patterns, picture of your body, picture of skid and eye movements, like you said, will be a very accurate predictor. We just published, by the way, recently speaking about eyes, a very nice study where in a car, just by looking at the driver, it can figure out what your blood sugar is because diabetics previously have not been able to get driver licenses sometimes because of the worry about them passing out because of hypogysemia.
Starting point is 01:11:51
So, there was a very nice study that showed that you could just by looking, have cameras pointed at the eyes, could actually figure out exactly what the blood sugar is. So, that kind of detection is, I think, fairly straightforward. It's a different question about what you can do about it. Before we go to the what you can do about it, I just want to go a little deeper on the predictive side. You brought up the Framingham model or the multi-ethnic study on atherosclerosis, the MESA model. These are the two most popular models by far for looking at a majorized adverse cardiac event risk prediction. But you needed something else to build those models, which was
Starting point is 01:12:23
enough time to see the outcome. In the Framingham cohort, which was the late 70s and early 80s, you then had the Framingham offspring cohort, and then you had to be able to follow these people with their LDLC and HDLC and triglycerides. Later eventually they incorporated calcium scores. If today we said, look, we want to be able to predict 30-year mortality, which is something no model can do today. This is a big pet peeve of mine is we generally talk about cardiovascular disease through
Starting point is 01:12:55
the lens of 10-year risk, which I think is ridiculous. We should talk about lifetime risk, but I would settle for 30 year risk frankly. And if we had a 30 year risk model where we could take many more inputs, I would absolutely love to be looking at the retina. I believe by the way, Zach, that retinal examination should be a part of medicine today for everybody. I would take a retinal exam over a hemoglobin A1C all day, every day. I'd never look at another A1C again if I could see the retina
Starting point is 01:13:26
of every one of my patients. But my point is even if effective today, we could define the data set and let's overdo it and we can prune things later, but we want to see these 50 things in everybody to predict every disease. Is there any way to get around the fact that we're going to need 30 years to see this come to fruition in terms of watching how the story plays out? Or are we basically going to say, no, we're going to do this over five years. It won't be that useful because a five-year predictor basically means you're already catching people in the throes of the disease. I'll say three words, electronic health records.
Starting point is 01:14:01
That turns out not to be the answer in the United States. Why? Because in the United States, we move around, we don't stay in any given healthcare system that long. So very rarely will I have all the measurements made on you, Peter, all your glycohemoglobin, all your blood pressures, all your clinic visits, all the imaging studies that you've had. However, that's not the case in Israel, for example.
Starting point is 01:14:28
In Israel, they have these HMOs, Health Maintenance Organizations, and one of them, Clarit, I have a good relationship with because they published all the big COVID studies looking at the efficacy of the vaccine. And why could they do that? Because they had the whole population available. And they have about 20, 25 years worth of data on all their patients in detail and family relationships. So if you have that kind of data and Kaiser Permanente also has that kind of data, I think you can actually come close. But you're not gonna be able to get retina, gate, voice,
Starting point is 01:15:06
because we still have to get those prospectively. I'm gonna claim that there are proxies, rough proxies, but for gate, falls, and for hearing problems, visits to the audiologist. Now these are noisier measurements. And so those of us who are data junkies like I am, always keep mumbling to ourselves, perfect is the enemy of good. Waiting 30 years to have the perfect data set is not the right answer to help patients
Starting point is 01:15:36
now. And there are things that we could know now that are knowable today that we just don't know because we haven't bothered to look. Give you a quick example. I did a study of autism using electronic health records maybe 15 years ago. And I saw there was a lot of GI problems. And I talked to a pediatric expert and they said, it was a little bit dismissive. They said, brain bad, tummy hurt.
Starting point is 01:16:01
I've seen a lot of inflammatory bowel disease. It just doesn't make sense to me that this is somehow effective brain function. To make a long story short, we did a massive study. We're looking forward to tens of thousands of individuals. And sure enough, we found subgroups of patients who had immunological problems associated with their autism. And they had type 1 diabetes, inflammatory bowel disease, lots of infections. Those were noble, but they were not known.
Starting point is 01:16:26
And I had, frankly, parents coming to me more thankful than for anything else I had ever done for them, clinically, because I was telling these parents, they weren't hallucinating that these kids have these problems. They just weren't being recognized by medicine because no one had the big wide angle to see these trends. So without knowing the field of Alzheimer's the way I do other fields, I bet you there are trends in Alzheimer's that you can pick up today by looking at enough patients
Starting point is 01:16:53
that you'll find some that have more frontotemporal components, some that have more effective components, some that have more of an infectious and immunological component. Those are noble today. Zach, you've already alluded to the fact that we're dealing with a customer, if the physician is the customer, who is not necessarily the most tech forward customer,
Starting point is 01:17:18
and truthfully, like many customers of AI, runs the risk of being marginalized by the technology if the technology gets good enough. And yet you need the customer to access the patient to make the data system better, to make the training set better. So how do you see the interplay over the next decade of that dynamic?
Starting point is 01:17:43
That's the right question. Cause in order for these AI models to work, you need a lot of data, a lot of patients. Where is that data going to come from? So there are some healthcare systems which like the Mayo Institute who think they can get enough data in that fashion. There are some data companies that are trying to get relationships with healthcare systems where they can get de-identified data. I'm betting on something else.
Starting point is 01:18:09
There is a trend where consumers are going to have increased access to their own data. The 21st Century Cures Act was passed by Congress and it said that patients should be given access to their own data programmatically. Now, they're not expecting your grandmother to write a program to access the data programmatically, but by having a right to it, it enables others to do so. So for example, Apple has something called Apple Health. It has this big heart icon on it. If you're one of the 800 hospitals that they've already hooked up with, Pass General or Brigham
Starting point is 01:18:42
Women's, and you're a patient there, if you authenticate yourself to it, if you give it your username and password, it will download into your iPhone, your labs, your meds, your diagnoses, your procedures, as well as all the wearable stuff, your blood pressure that you get as an outpatient and various other forms of data that's already happening now. There's not a lot of companies that are taking advantage of that. But right now that data is available on tens of millions of Americans. Isn't it interesting, Zach,
Starting point is 01:19:11
how unfriendly that data is in its current form? I'll give you just a silly example in our practice. So if we send a patient to LabCorp or Boston Heart or pick your favorite lab, and we want to generate our own internal reports based on those where we want to do some analysis on that, lay out trend sheets. We have to use our own internal software.
Starting point is 01:19:36
It's almost impossible to scrape those data out of the labs because they're sending you PDF reports, their APIs are garbage. Nothing about this is user friendly. So even if you have the My Heart thing, or whatever the My Health thing come on your phone, it's not navigable. It's not searchable.
Starting point is 01:19:57
It doesn't show you trends over time. Is there a more user hostile industry from a data perspective than the health industry right now? No, no. And there's a good reason why, because they're keeping you captive. But Peter, the good news is, you're speaking to a real nerd.
Starting point is 01:20:15
Let me tell you two ways where we could solve your problem. One, if it's in the Apple health thing, someone can actually write a program, an app on the iPhone, which will take those data as numbers and not have to scrape it. And it can run it through your own trending programs. You could actually use it directly. Also, Gemini and GPT-4, you can actually give it those PDFs.
Starting point is 01:20:37
And actually, with the right prompting, it will actually take those data and turn them into tabular spreadsheets. We can't do that because of HIPAA, correct? If the patient gets it from the patient portal, absolutely you can do that. The patient can do that, but I can't use a patient's data that way. If the patient gives it to you, absolutely. Really? Oh yes. But it's not de-identified.
Starting point is 01:21:00
Doesn't matter. If a patient says, Peter, you can take my 50 lab core reports for the last 10 years and you can run them through ChatGPT to scrape it out and give me an Excel spreadsheet that will perfectly tabularize everything that we can then run into our model to build trends and look for things. I didn't think that was doable actually. So, it's not doable through ChatGPT because your lawyers would say, Peter, you're gonna get a million dollars in fines from HIPAA. I'm not a shill for Microsoft. I don't own
Starting point is 01:21:32
any stock. But if you do GPT on the Azure cloud, that's HIPAA protected, you absolutely can use it with patient consent. 100% you can do it. GPT is being used with patient data out of Stanford right now. Epic's using GPT-4, and it's absolutely legitimately usable by you. People don't understand that. We've now just totally bypassed OCRs. We do not need to waste our time for people not in the acronyms optical character recognition, which is 15 years ago what we
Starting point is 01:22:04
were trying to do to scrape this data. Peter, let me tell you, there's New England Journal of Medicine. I'm on the editorial board there and we just published three months ago a picture of them weak back of this 72 year old and it looks like a bunch of red marks. To me, it looks like someone to scratch themselves and it says blah, blah, blah. They had trouble sleeping. This is the image of the week. Image of the week. And I took that whole thing and I took out one important fact and then gave it to GPT-4, the image and the text.
Starting point is 01:22:34
And it came up with the two things they thought it would be, either bleomycin toxicity, which I don't know what that looks like, and shiitake mushroom toxicity. What I'd removed is the fact that guy had eaten mushrooms the day before. So this thing just like looking at the picture. GPT-4 spit this out? Yes.
Starting point is 01:22:55
I don't think most doctors know this, Zach. I don't think most doctors understand. First of all, I can't tell you how many times I get a rash. Well, I try to send a picture to my doctor or my kid gets a rash and I'm trying to send a picture to their pediatrician and they don't know what it is. And it's like, we're rubbing two sticks together and you're telling me about the Zippo lighter. Yes. And that's what I'm saying is patients without primary care doctors. I know I keep repeating myself. They understand that they have a Zippo lighter waiting three months because of a rash or the symptoms. They say, I they have a Zippo lighter, waiting three months because of a rash or these symptoms. They say, I'll use this Zippo lighter.
Starting point is 01:23:28
It's better than no doctor for sure. And maybe better. That's now. Quickly illustrated. I don't know squat about the FDA. And so I pulled down from the FDA the adverse event reporting files. It's a big zip file, compressed file.
Starting point is 01:23:43
And it went to GPT-4, please analyze this data. And it says unzipping based on this table. I think this is about the adverse events and this is the locations. What do you want to know? I say, tell me what are the adverse events for disease modifying drugs for arthritis. It says, Oh, to do that, I'll have to join these two tables and it just does it. It creates its own Python code.
Starting point is 01:24:05
It does it. And it gives me a report. Is this a part of medical education now? You're at Harvard, right? You're at one of the three best medical schools in the United States, arguably, in the world. Is this an integral part of the education of medical students today?
Starting point is 01:24:19
Do they spend as much time on this as they do histology, where I spent 1, thousand hours looking at slides under a microscope that I've never once tried to understand. Again, I don't want to say there wasn't a value in doing that. There was, and I'm grateful for having done it, but I want to understand the relative balance of education. It's like the stethoscope.
Starting point is 01:24:41
Arguably, we should be using things other than the stethoscope. Let me make sure I don't get fired, or at least being severely, by telling you that George Daley, our dean of the medical school, has said explicitly he wants to change all of medical education so these learnings are infused throughout the four years, but it's going to take some doing. Let's now move on to the next piece of medicine. So we've gone from purely the recognition image-based to how do I combine image with voice, story, text. You've made a very compelling case that we don't need any more technological breakthroughs to augment those. It's purely a data set problem at this point and a willingness.
Starting point is 01:25:24
those, it's purely a data set problem at this point and a willingness. Let's now move to the procedural. Is there in our lifetimes, say Zach, the probability that if you need to have a radical prostatectomy, which currently by the way is never done open, this is a procedure that the DaVinci, a robot, has revolutionized. There's no blood loss anymore. When I was a resident, this was one of the bloodiest operations we did. It was the only operation, by the way, for which we had the patients donate their own blood two months ahead of time. That's how guaranteed it was that they were going to need blood transfusions. So we just had to hell with it. Come in a couple of months before,
Starting point is 01:26:00
give your own blood because you're going to need at least two units following this procedure. Today, it's insane how successful this operation is on a large part of the robot but the surgeon needs to move the robot. Are we getting to the point where that could change? So let me tell you where we are today. Today there's been studies where it's collected a bunch of YouTube videos of surgery and traded up one of these generative models. So it says, Oh, they're putting on the scalpel to cut this ligament. And by the way, that's too close to the blood vessel.
Starting point is 01:26:35
They should move it a little bit to the side. That's already happening based on what we're seeing with robotics in the general world, I think the DaVinci controlled by a robot 10 years is a very safe bet. It's a very safe bet. In some ways, 10 years is nothing. It's nothing, but it's a very safe bet. The fact is, right now, I can do a better job, by the way, just to go back to our previous
Starting point is 01:27:02
discussion, giving you a genetic diagnosis based on your findings with the primary care provider interpreting a genomic test. So are you using that example, Zach, because it's a huge data problem? In other words, that's obvious that you would be able to do that because the amount of data, I mean, there's 3 billion base pairs to be analyzed. So of course you're going to do a better job. But linking it to symptoms. Yeah. Yeah. But you're saying surgery is a data problem because if you turn it into a pixel problem. Pixel and movement. And degrees of freedom. Yeah. That's it. Remember, there's a lot of degrees of freedom in moving a car around traffic. And by
Starting point is 01:27:42
the way, lives are on the line there too. Now, medicine is not the only job where lives are at stake. Driving a ton of metal at 60 miles per hour in traffic is also putting lives at stake. And last time I looked, there's several manufacturers who are saying that, or some appreciable fraction of that effort, they are controlling multiple degrees of freedom with a robot. Yeah, I very recently spoke with somebody, I won't name the company, I suppose, but it's one of the companies that's deep in the space of autonomous vehicles. And they very boldly stated, they made a pretty compelling case for it. That if every vehicle on the road was at their level of technology in autonomous
Starting point is 01:28:28
driving, you wouldn't have fatalities anymore. But the key was that every vehicle had to be at that level. I don't know if you know enough about that field, but does that sense check to you? Well, first of all, I'm a terrible driver. I am a better driver. It's not for ABB, but in fact is I'm a better driver because I'm not on a Tesla because I'm a terrible driver. And there's actually a very good message for medicine because I will paraphrase this. I know enough to know that I need to jiggle the steering wheel when I'm driving with a Tesla because otherwise it will assume that I'm just zoning out. But I didn't realize is this. I'm very bad. I'll pick up my phone and I'll look at it.
Starting point is 01:29:07
I didn't realize it was looking at me and says, because Zach put down the phone. So I, okay, I put down three minutes later. I pick it up again and it says, okay, that's it. I'm switching off autopilot. So it switches off autopilot and now I have to pay attention, full attention. Then I get home and it says, all right, that was bad. You do that four more times. I'm switching off autopilot until the next software update. And the reason I mentioned that is it takes a certain amount of confidence to do that
Starting point is 01:29:33
to your customer base saying, I'm switching off the thing that they bought me for. In medicine, how likely is it that we're going to fall asleep at the wheel if we have an AI thinking for us? It's a real issue. We know for a fact, for example, back in the nineties, that doses for a drug like a Dantatron, where people would talk endlessly about how frequently should be given it with what dose. The moment you put it in the order entry system, 95% of doctors would just use the default there.
Starting point is 01:30:00
And so how in medicine are we going to keep doctors awake at the wheel? And will we dare to do the kind of challenges that I just described the car doing? So just to get back to it, I do believe because of what I've seen with autonomy and robots, that as fancy as we think that is, controlling a dementia robot will probably have less bad outcomes. Every once in a while someone nicks something and you have to go into full surgery or they go home and they die on the way home because they exsanguinate. I think it's just going to be safer. It's just unbelievable for me to wrap my head around that.
Starting point is 01:30:40
But truthfully, it's impossible for me to wrap my head around what's already happened. So I guess I'll try to retain the humility that says I reserve the right to be startled. Again, there are certain things that seem much easier than others. Like I have an easier time believing we're going to be able to replace interventional cardiologists where the number of degrees of freedom, the complexity, and the relationship between what the image shows, what the cath shows and what the input is, the stent, that gap is much narrower. Yeah, I can see a bridge to that. But when you talk about doing a Whipple procedure, when you talk about what it means to cell
Starting point is 01:31:19
by cell take a tumor off the superior mesenteric vessels. I'm thinking, oh my God. Since we're on record, I'm going to say, I'm talking about your routine prostate removal. Yeah, first 10 years, I would take that bet today. Wow. Let's go one layer further. Let's talk about mental health. This is a field of medicine today that I would also argue is grossly underserved. Everything you've said to date resonates. I completely agree from my own experience that the resources in pediatrics and primary care, I mean, these things are unfortunate at the moment.
Starting point is 01:31:57
Harvard has, I think, 60% of undergraduates are getting some sort of mental health support and it's completely outdoing all the resources available to the university health services. And so we have to outsource some of our mental health and this is a very richly endowed university. In general, we don't have the resources. So here we live in a world where I think the evidence is very clear
Starting point is 01:32:19
that when a person is depressed, when a person is anxious, when a person has any sort of mental or emotional illness, pharmacotherapy plays a role, but it can't display psychotherapy. You have to be able to put these two things together. And the data would suggest that the knowledge of your psychotherapist is important,
Starting point is 01:32:38
but it's less important than the rapport you can generate with that individual. Now, based on that, do you believe that the most sacred, protected, if you want to use that term, profession within all of medicine will then be psychiatry? I'd like to think that. If I had a psychiatric GPT speaking to me, I wouldn't think that it understood me. On the other hand, back in the 1960s or 70s, there was a program called ELIZA, and it was a simple pattern matching program.
Starting point is 01:33:13
It would just emulate what's called a Rogerian therapist, where I really hit my mother. Why do you say you hit your mother? Oh, it's because I don't like the way she fed me. What is it about the way she fed you? Just very, very simple pattern matching. And this ELISA program, which was developed by Joe Weitzembaume at MIT, A, his own secretary would lock herself in her office to have sessions with this thing, because it's non-general.
Starting point is 01:33:41
This was in the 80s? 70s or 60s. Wow. Yeah. And it turns out that there's a large group of patients who actually would rather have a non-human, non-judgmental person who remembers what they've said from last time, shows empathy verbally. Again, I wrote this book with Peter Lee and Peter Lee made a big deal in the book about how GPT-4 was showing empathy. In the book, I argued with him that this is not that big a deal.
Starting point is 01:34:10
And I said, I remember from medical school being told that some of the most popular doctors are popular because they're very deep empaths, not necessarily the best doctors. And so I said, you know, for certain things, that's just me. I could imagine a lot of, for example, cognitive behavioral therapy being done and be found acceptable by a subset of human beings. It's not wouldn't be for me. I'd say I'm just speaking to some stupid program. But if it's giving you insight into yourself and it's based on the wisdom called for millions of patients, who's to say that it's worse and it's certainly not judgmental
Starting point is 01:34:47
and maybe it'll bill less. So Zach, you're born probably just after the first AI boom. You come of age intellectually, academically in the second and now in the mature part of your career, when you're at the height of your esteem, you're riding the wave of this third version, which I don't think anybody would argue is going anywhere. As you look out over the next decade, and we'll start with medicine, what are you most excited about and what are you most afraid of with respect to AI? specifically with regard to medicine what I'm most concerned about is How it could be used by the medical establishment To keep things the way they are to pour concrete over practices what I'm most excited about is alternative
Starting point is 01:35:45
business models young doctors who create businesses outside the mold of hospitals. Hospitals are these very, very complex entities. They make billions of dollars, some of the bigger ones, but with very small margins, one to two percent. When you make, have huge revenue, but very small margins, you're going to be very risk averse and you're not going to want to change. And so what I'm excited about is the opportunity for new businesses and new ways of delivering to patients insights that are data driven. What I'm worried about is hospitals doing a bunch of information blocking and regulations that will make it
Starting point is 01:36:28
harder for these new businesses to get created. Understandably, they don't want to be disrupted. That's the danger. In that latter case or that case that you're afraid of, Zach, can patients themselves work around the hospitals with these new companies, these disruptive companies and say, look, we have the legal framework that says I own my data as a patient. I own my data. Believe me, we know this in our practice. Just because our patients own the data doesn't make it easy to get. There is no aspect of my practice that is more miserable and more inefficient than data acquisition from hospitals.
Starting point is 01:37:06
It's actually comical. Absolutely comical and I do pay hundreds of dollars to get my data from my patients with rare and unknown diseases in this network, extracted from the hospitals because it's worth it to pay someone to do that extraction. Yeah, but now I'm telling you it is doable. So you're saying because of that that are you confident that the legal framework for patients to have their data coupled with AI?
Starting point is 01:37:31
And companies do you think that that will be a sufficient hedge against your biggest fear? I think that unlike my 10-year prostatectomy by robot prediction I'm not as certain but I would give better than 50% odds that in the next 10 years, there'll be a company, at least one company that figures out how to use that patient's right to access through dirty APIs, using AI to clean it up, provide decision support with human doctors or health professionals to create alternative businesses, I am convinced because the demand is there. And I think that you'll see companies
Starting point is 01:38:12
that are even willing to put themselves at risk. What I mean by that are willing to take the medical risk on that if they do better than a certain level of performance, they get paid more. Or if they do worse. They don't get paid, yeah. I believe there are companies that are gonna be in that space, but that is because I don't want
Starting point is 01:38:32
to underestimate the medical establishment's ability to squish threats, so we'll see. Okay, now let's just pivot to AI outside of medicine. Same question, what are you most afraid of over the next decade? So maybe we're not talking about self-awareness and Skynet, but next decade, what are you most afraid of and what are you most excited about? What I'm most afraid of is a lot of the ills
Starting point is 01:39:00
of social networks being magnified by use of these AIs to further accelerate cognitive chaos and vitriol that fills our social experiences on the net. It could be used to accelerate them. So that's my biggest fear. I saw an article two weeks ago that was an individual, I can't remember if they were currently in or formerly part of the FBI. They stated that they believed, I think it was somewhere between 75 and 90% of quote unquote individuals on social media were not in fact individuals. I don't know if you spend enough time on social media to have a point of view on that.
Starting point is 01:39:43
Unfortunately, I have to admit to the fact that my daughter, who's now 20 years old, but four years ago, she bought me a mug that says on it, Twitter addict. I spent enough time. I would not be surprised if some large fraction are bots could get worse and it's going to be harder to actually distinguish reality from human beings. Harder and harder and harder. That's the real problem. We are fundamentally social animals and if we cannot understand our social context in most of our interactions it's going to
Starting point is 01:40:16
make us crazy or I should say crazier. And my most positive aspect is I think that these tools can be used to expand the creative expression of all people. If you're a poor driver like me, I'm going to be a better driver. If you're a lousy musician, but have a great ear, you're going to be able to express yourself musically in ways that you could not do before. I think you're going to see filmmakers who were never meant to be filmmakers before express themselves. I think human expression is going to be expanded
Starting point is 01:40:51
because just like printing press allowed all sorts of, in fact, it's a good analogy because the printing press also created a bunch of wars because it made a lot of people to clear their opposition to the church and so on, enabled a number of bad things to happen, but it allowed also expression of all literature in the ways that would have not been possible without the printing press. I'm looking forward to human expression and creativity. I can't imagine you haven't played with some of the picture generation or music generation capabilities of AI or if you haven't, I strongly recommend. You're going to be amazed. I have not. I am ashamed maybe to admit my interactions with AI are limited to really chat GPT for
Starting point is 01:41:30
and basically problem solving. Solve this problem for me. And by the way, I think I'm doing it at a very JV level. I could really up my game there. Just before we started this podcast, I thought of a problem I've been asking my assistant to solve because A, I don't have the time to solve it and I'm not even sure how I would solve it. It would take me a long time. I've been asking her to solve it and it's actually pretty hard. Then I realized,
Starting point is 01:41:51
oh my God, why am I not asking ChatGPT4 to do it? I just started typing in the question. It's a bit of an elaborate question. As soon as we're done with this podcast, I'll probably go right back to it. I haven't done anything creatively with it. What I will say is, what does this mean for human greatness? So right now, if you look at a book that's been written and someone who's won a Pulitzer Prize, you sort of recognize, like I don't know if you read Sid Mukherjee, right? He's one of my favorite writers when it comes to writing about science and medicine. When I read something that Sid has written, I think to myself there's a reason that he is so special. He and he almost alone can do something we can't do. I've written a book, doesn't matter. I could write a hundred books. I'll never write like Sid.
Starting point is 01:42:41
And that's okay. I'm no worse a person. I'm no worse a person than Sid. But he has a special gift that I can appreciate, just as we could all appreciate watching an exceptional athlete or an exceptional artist or musician. Does it mean anything if that line becomes blurred? That's the right question. And yes, Sid writes like poetry. Here's an answer which I don't like.
Starting point is 01:43:06
I've heard many times people said, oh, you know that Deep Blue beat Kasparov in chess, but chess is more popular than it ever was, even though we know that the best chess players of the world are computers. So that's one answer. I don't like that answer at all. Because if we create SID GPT and SID wrote Alzheimer's, the second greatest malady, and it wrote it in full SID style, but it was not SID, but it was just as empathic, family references.
Starting point is 01:43:39
The weaving of history with story with science. If it did that and it was just a computer, how would you feel about it, Peter? I mean, Zach, you are asking the jugular question. I would enjoy it, I think, just as much, but I don't know who I would praise. Maybe I have in me a weakness slash tendency to want to idolize.
Starting point is 01:44:00
You know, I'm not a religious person, so my idols aren't religious, but I do tend to love to see greatness. I love to look at someone who wrote something who's amazing and say, that amazes me. I love to be able to look at the best driver in the history of Formula One and study everything about what they did to make them so great. So I'm not sure what it means in terms of that.
Starting point is 01:44:22
I don't know how it would change that. I grew up in Switzerland in Geneva. And even though I have this American accent, both my parents were from Poland. And so the reason I have an American accent is I went to international school with a lot of Americans. All I read was whatever my dad would get me from England in science fiction.
Starting point is 01:44:39
So I'm a big science fiction fan. So let me go science fiction on you to answer this question. It's not gonna be in 10 years, but it could be in 50 years. You'll have idols and idols will be, yes, Gregorovitch wrote a great novel, but you know, AI 521, their understanding of the human condition is wonderful. I cry when I read their novels. They'll be a part of the ecosystem. They'll be entities within us, whether they are self aware or not will become a philosophical question. Let's not go that narrow path that
Starting point is 01:45:10
discussing rabbit hole where I wonder, does Peter actually have consciousness or not? Does he have the same processes as I do? We won't know that about these or maybe we will, but will it matter if they're just among us? And they'll have brands, they'll have companies around them. They'll be superstars and they'll be Dr. Fubar from Kansas trained on iuredific medicine. The key person for our alternative medicine, not a human, but we love what they do. Okay, last question. How long until from at least an intellectual
Starting point is 01:45:49
perspective, we are immortal? So if I died today, my children will not have access to my thoughts and musings any longer. Will there be a point at which during my lifetime, an AI can be trained to be identical to me, at least from a goalpost perspective, to the point where after my death, my children could say, dad, what should I do about this situation? And it can answer them in a way that I would have. It's a great question because that was an early business plan
Starting point is 01:46:29
that was generated shortly after GPT-4 came out. In fact, I was talking very briefly to Mark Cuban because he saw GPT-4. I think he got trademarks or copyrights on his voice, all his work and likeness so that someone could not create a mark who responded in all the ways he does. And I'll tell you that it sounds crazy, but there's a company called rewind.ai and I have it running right now. And everything that appears on my screen, it's recording every sound that it hears, it's recording.
Starting point is 01:47:08
And if characters appear on the screen, it'll OCR them. If a voice appears, and then if I have a question, I say, when did I speak with Peter Altea? He'll find it for me. I'll say, who was I talking about? AI and Alzheimer's. And they'll find this video on a timeline. How many terabytes of data is this, Zach?
Starting point is 01:47:31
Amazingly small. It's just gigabytes. How is that possible? Because A, it compresses it down in real time with using Apple silicon. And second of all, you and I, you're old and you don't realize that gigabytes are not big on a standard Mac that has a terabyte. That's a thousand gigabytes. And so you can compress audio immensely.
Starting point is 01:47:53
It's actually not taking video. It's just taking multiple snapshots every time the screen changes by a certain amount. Yeah. It's not trying to get video resolution per se. No, and it's doing it. And I can see a timeline. It's quite remarkable. And so that is enough, in my opinion, data,
Starting point is 01:48:11
so that with enough conversations like this, someone could create a pretty good approximation of at least public Zach. So then the next question is, is Zach willing to have Rewind AI on a recording device, his phone, with him 24-7 in his private moments, in his intimate moments, when he is arguing with his wife, when he's upset at his kids, when he's having the most amazing experience with his postdoc? If you think about the entire range of experiences we have from the good, the bad, the ugly,
Starting point is 01:48:49
those are probably necessary if we want to formulate the essence of ourselves. You envision a day in which people can say, look, I'm willing to take the risks associated with that. And there are clear risks associated with doing that, but I'm willing to take those risks in order to have this legacy, this data set to be turned into a legacy? I think it's actually pretty creepy to come back from the dead to talk to your children. So I actually have other goals.
Starting point is 01:49:11
Here's where I take it. We are being monitored all the time. We have iPhones, we have Alexa devices. I don't know what is actually being stored by whom and what. And people are gonna use this data in ways that we do or don't know. I feel it's us, the little guy, if we have our own copy, and we can say, well, actually, look, this is what I said then.
Starting point is 01:49:31
Yeah, that was taken out of context. Yeah, that was taken out of context. And I can do it. I have an assistant that can just find it and find exactly and find all the times I said it. I think that's good. I think it's messing with your kid's head to have you come back from the dead and give advice, even though they might be tempted.
Starting point is 01:49:51
Technically, I think it's gonna be not that difficult. And again, speaking about rewind AI, again, I have no stake in them. I think I might have paid them for a license to run on my computer, but the microphone is always on. So when I'm talking to students in my office, it's taking that down.
Starting point is 01:50:09
So there's some moments in my life where I don't wanna be on record. There are big chunks of my life that are actually being stored this way. Well, Zach, this has been a very interesting discussion. I've learned a lot. I probably came into this discussion with about the same level of knowledge,
Starting point is 01:50:24
maybe slightly more than the average person, but clearly not much more on just the general principles of AI, the evolution of AI. I guess if anything surprises me, and a lot does, but nothing surprises me more than the time scale that you've painted for the evolution within my particular field and your particular field, which is medicine. I had no clue that we were getting this close to that level of intelligence. Peter, if I were you, this is not an offer cause I'm too busy, but you're a cable guy and you have a great network. If I was running the clinic that you're running, I would take advantage of now. I would get those videos and those sounds and get all my patients with, of course, their
Starting point is 01:51:11
consent to be part of this and to actually follow their progress. Not just the way to report it, but by their gait, by the way they look. You can do great things in what you're doing and advance the state of art. You're asking who's going to do it. You're doing some interesting things. You could be pushing the envelope using these technologies as just another very smart, comprehensive assistant. Sack, you've given me a lot to think about. I'm grateful for your time and obviously for
Starting point is 01:51:40
your insight and years of dedication that have allowed us to be sitting here having this discussion. Thank you very much. It was a great pleasure. Thank you for your insight and years of dedication that have allowed us to be sitting here having this discussion. Thank you very much. It was a great pleasure. Thank you for your time. Thank you for listening to this week's episode of The Drive. It's extremely important to me to provide all of this content without relying on paid ads. To do this, our work is made entirely possible by our members, and in return, we offer exclusive member-only content
Starting point is 01:52:04
and benefits above and beyond what is available for free. So if you want to take your knowledge of this space to the next level, it's our goal to ensure members get back much more than the price of the subscription. Premium membership includes several benefits. First, comprehensive podcast show notes that detail every topic, paper, person, and thing that we discuss in each episode. And the word on the street is, nobody's show notes rival ours. Second, monthly Ask Me Anything or AMA
Starting point is 01:52:32
episodes. These episodes are comprised of detailed responses to subscriber questions, typically focused on a single topic, and are designed to offer a great deal of clarity and detail on topics of special interest to our members. You'll also get access to the show notes for these episodes, of course. Third, delivery of our premium newsletter, which is put together by our dedicated team of research analysts. This newsletter covers a wide range of topics related to longevity and provides much more detail than our free weekly newsletter. Fourth, access to our private podcast feed that provides you with access to every episode including AMAs, Sans, the Spiel you're listening to now, and in your regular podcast feed.
Starting point is 01:53:15
Fifth, the Qualis, an additional member-only podcast we put together that serves as a highlight reel featuring the best excerpts from previous episodes of The Drive. This is a great way to catch up on previous episodes without having to go back and listen to each one of them. And finally other benefits that are added along the way. If you want to learn more and access these member-only benefits you can head over to peteratiamd.com forward slash subscribe. You can also find me on YouTube, Instagram and Twitter, all with the handle peteratiamd. You can also leave us a review on Apple Podcasts or whatever podcast player you use. This podcast is for general informational purposes only and does not constitute the
Starting point is 01:53:57
practice of medicine, nursing or other professional health care services, including the giving of medical advice. No doctor-patient relationship is formed. The use of this information and the materials linked to this podcast is at the user's own risk. The content on this podcast is not intended to be a substitute for professional medical advice, diagnosis, or treatment. Users should not disregard or delay in obtaining medical advice from any
Starting point is 01:54:22
medical condition they have, and they should seek the assistance of their healthcare professionals for any such conditions. Finally, I take all conflicts of interest very seriously. For all of my disclosures. you